{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garbage Classifier\n",
    "\n",
    "Let's build a garbage classifier with machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model\n",
    "\n",
    "We will start with downloading an existing data model.\n",
    "For this we will use this one from kaggle [garbage-classification](https://www.kaggle.com/datasets/asdasdasasdas/garbage-classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "path = Path('Garbage classification/Garbage classification')\n",
    "if not path.exists():\n",
    "    zipfile.ZipFile('garbage-classifier-dataset.zip').extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.transforms import get_image_files\n",
    "\n",
    "fns = get_image_files(path)\n",
    "fns"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "When we create our own dataset from images downloaded from the internet it's usually a good practice to verify that the images can be opened. In this example it's not really needed since we are working with a curated set."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.utils import verify_images\n",
    "\n",
    "failed = verify_images(fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "For machine learning to be able to use our dataset the set needs to be constructed in a consistent way. For this we can use a DataBlock which is a generic container used to quickly build 'Datasets' and 'DataLoaders'."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.augment import Resize\n",
    "from fastai.data.transforms import RandomSplitter, parent_label\n",
    "from fastai.vision.data import ImageBlock\n",
    "from fastai.data.block import DataBlock, CategoryBlock\n",
    "\n",
    "garbage = DataBlock(\n",
    "    blocks = (ImageBlock, CategoryBlock),\n",
    "    get_items = get_image_files,\n",
    "    splitter = RandomSplitter(valid_pct=0.2, seed=42),\n",
    "    get_y=parent_label,\n",
    "    item_tfms=Resize(128))\n",
    "\n",
    "dls = garbage.dataloaders(path, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see some of the files that we loaded."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch(max_n=10, nrows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Traing our model\n",
    "We are now ready to train our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how it did out of the box. One way is to build a Confusion Matrix"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.interpret import ClassificationInterpretation\n",
    "\n",
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can also see where our model made its errors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_top_losses(5, nrows=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sharing our model\n",
    "For now, though this will do. Let's export our trained model to a file."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "learn.export('garbage-classifier.pkl')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
